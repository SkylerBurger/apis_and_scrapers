{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from random import randint\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter an Instagram profile name as a string below\n",
    "# And then un-comment the line\n",
    "\n",
    "# profile_name = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instagram_url = f'https://www.instagram.com/{profile_name}'\n",
    "max_scroll_secs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshots = []\n",
    "def snapshot(browser):\n",
    "    global snapshots\n",
    "    snapshots.append(browser.page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attribution for scrolling mechanism:\n",
    "# https://stackoverflow.com/questions/20986631/how-can-i-scroll-a-web-page-using-selenium-webdriver-in-python#27760083\n",
    "\n",
    "def scroll_and_snapshot(browser, max_scroll_secs):\n",
    "    SCROLL_PAUSE_TIME = 1\n",
    "\n",
    "    # Get scroll height\n",
    "    last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    end_time = time.time() + max_scroll_secs\n",
    "    \n",
    "    while time.time() < end_time:\n",
    "        # Scroll down to bottom\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        # Wait to load page\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "        # Calculate new scroll height and compare with last scroll height\n",
    "        new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height <= last_height:\n",
    "            snapshot(browser)\n",
    "            break\n",
    "        # Create HTML snapshot\n",
    "        snapshot(browser)\n",
    "        last_height = new_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_image_tags(snapshots):\n",
    "    \n",
    "    image_tags = []\n",
    "    \n",
    "    for html in snapshots:\n",
    "\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        image_tags += soup.find_all('img', class_='FFVAD')\n",
    "        \n",
    "    return set(image_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture(snapshots, browser):\n",
    "        \n",
    "    image_tags = collect_image_tags(snapshots)\n",
    "\n",
    "    for index, image in enumerate(image_tags):\n",
    "        browser.get(image['src'])\n",
    "        images = browser.find_elements_by_tag_name('img')\n",
    "        # Edit file name f-string below  as needed\n",
    "        images[0].screenshot(f'./screenshot_{index}.png')\n",
    "        wait_time = randint(1, 2)\n",
    "        time.sleep(wait_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If you need to download/update chromedriver\n",
    "# https://sites.google.com/a/chromium.org/chromedriver/\n",
    "\n",
    "browser = webdriver.Chrome('../utilities/chromedriver')\n",
    "\n",
    "browser.get(instagram_url)\n",
    "\n",
    "scroll_and_snapshot(browser, max_scroll_secs)\n",
    "\n",
    "# ONLY call line below if you want to risk saving a TON of images\n",
    "# capture(snapshots, browser)\n",
    "\n",
    "# 2 lines below report # of tags captured w/o saving images\n",
    "images = collect_image_tags(snapshots)\n",
    "print(f'Image Links Captured: {len(images)}')\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('apis-and-scrapers': venv)",
   "language": "python",
   "name": "python38264bitapisandscrapersvenvf2140220de3048d48d920259101581f4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}