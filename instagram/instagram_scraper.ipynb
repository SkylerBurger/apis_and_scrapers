{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instagram Scraper\n",
    "\n",
    "This notebook is an exploration of a few difficulties in web scraping Instagram.\n",
    "\n",
    "If you like this example, check out my [`insta_builder.py`](./insta_builder.py) module where I implement the Builder design pattern to create representations of an Instagram profile. This example could be extended to handle profile from other social media platforms by creating a new builder and profile class for each platform.\n",
    "\n",
    "## Challenges:\n",
    "\n",
    "1. GET requests to Instagram return executable JavaScript rather than HTML content.\n",
    "  - To get past this issue I learned how to use Selenium which executes the JavaScript included in the response from Instagram just as a browser would. This gathers and renders the actual HTML content so I can scrape it.\n",
    "2. Instagram has a soft login-wall to keep clients that are not logged in from viewing the full extent of a profile's public content.\n",
    "  - When researching how to scroll through a page of unknown length in Selenium, I came across an approach that manipulates the `window` object directly to continue scrolling. Luckily, this direct approach works even after Instagram renders their soft login-wall to the page.\n",
    "3. Instagram dynamically populates and depopulates images from the browser as you scroll through a profile.\n",
    "  - To make sure that I capture all of the images as I scroll, I set up an algorithm that takes a 'snapshot' of the current HTML content of the page and then scrolls to the bottom of the page. Scrolling to the bottom of the page causes new content to render and old content to depopulate from the page. It then repeats this process of taking a snapshot and scrolling until it notices that the bottom of the page is no longer extending. I then extract all the image tags from the HTML snapshots and remove duplicates by running them through a set.\n",
    "4. Recently (09/2020), Instagram changed their initial preview of public profiles when a user is not logged in. Instead of automatically loading images upon scrolling to the bottom of the page, they currently show a few images and a 'show more' button.\n",
    "  - To get the page back into a state where images load automatically upon scrolling, I had to use Chrome Dev Tools to identify potential class names to use in targeting the 'show more' button element. With class names in hand I was able to write a few lines that tell the Selenium WebDriver how to locate the button and then to execute a click action on it. Once the button was clicked and scrolling was restored, the remainder of my previous code continued to work as expected.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import time\n",
    "from random import randint\n",
    "\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def snapshot(browser):\n",
    "    global snapshots\n",
    "    snapshots.append(browser.page_source)\n",
    "\n",
    "\n",
    "def scroll_and_snapshot(browser, max_scroll_secs):\n",
    "    SCROLL_PAUSE_TIME = 1\n",
    "    last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "    end_time = time.time() + max_scroll_secs\n",
    "    \n",
    "    # Attribution for scrolling mechanism:\n",
    "    # https://stackoverflow.com/questions/20986631/how-can-i-scroll-a-web-page-using-selenium-webdriver-in-python#27760083\n",
    "    while time.time() < end_time:\n",
    "        # Scroll down to bottom\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        # Wait to load page\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        # Calculate new scroll height and compare with last scroll height\n",
    "        new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        snapshot(browser)\n",
    "        \n",
    "        if new_height <= last_height:\n",
    "            break\n",
    "        else: \n",
    "            last_height = new_height\n",
    "\n",
    "\n",
    "def collect_image_tags(snapshots):\n",
    "    image_tags = []\n",
    "    \n",
    "    for html in snapshots:\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        image_tags += soup.find_all('img', class_='FFVAD')\n",
    "        \n",
    "    return set(image_tags)\n",
    "\n",
    "\n",
    "def capture(snapshots, browser):  \n",
    "    image_tags = collect_image_tags(snapshots)\n",
    "\n",
    "    for index, image in enumerate(image_tags):\n",
    "        browser.get(image['src'])\n",
    "        images = browser.find_elements_by_tag_name('img')\n",
    "        # Edit file name f-string below  as needed\n",
    "        images[0].screenshot(f'./screenshot_{index}.png')\n",
    "        wait_time = randint(1, 2)\n",
    "        time.sleep(wait_time)\n",
    "\n",
    "\n",
    "def create_browser():\n",
    "    browser = webdriver.Chrome('../utilities/chromedriver')\n",
    "    return browser\n",
    "\n",
    "\n",
    "def click_show_more_button(browser):\n",
    "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    button = browser.find_element_by_class_name('z4xUb')\n",
    "    button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Image Links Captured: 361\n"
    }
   ],
   "source": [
    "# Execution\n",
    "\n",
    "# Enter an Instagram profile name as a string below\n",
    "# And then un-comment the line\n",
    "\n",
    "# profile_name = ''\n",
    "instagram_url = f'https://www.instagram.com/{profile_name}'\n",
    "max_scroll_secs = 300\n",
    "snapshots = []\n",
    "\n",
    "browser = create_browser()\n",
    "browser.get(instagram_url)\n",
    "click_show_more_button(browser)\n",
    "scroll_and_snapshot(browser, max_scroll_secs)\n",
    "images = collect_image_tags(snapshots)\n",
    "print(f'Image Links Captured: {len(images)}')\n",
    "\n",
    "# ONLY call line below if you want to risk downloading a lot of images\n",
    "# capture(snapshots, browser)\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('apis-and-scrapers': venv)",
   "language": "python",
   "name": "python38264bitapisandscrapersvenvf2140220de3048d48d920259101581f4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}