{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instagram Scraper\n",
    "\n",
    "This notebook is an exploration of a few difficulties in web scraping Instagram.\n",
    "\n",
    "If you like this example, check out my [`insta_builder.py`](https://github.com/SkylerBurger/apis_and_scrapers/blob/master/instagram/insta_builder.py) module where I implement the Builder design pattern to create representations of an Instagram profile. This example could be extended to handle profile from other social media platforms by creating a new builder and profile class for each platform.\n",
    "\n",
    "## Challenges:\n",
    "\n",
    "1. GET requests to Instagram return executable JavaScript rather than HTML content.\n",
    "  - To get past this issue I learned how to use Selenium which executes the JavaScript included in the response from Instagram just as a browser would. This gathers and renders the actual HTML content so I can scrape it.\n",
    "2. Instagram has a soft login-wall to keep clients that are not logged in from viewing the full extent of a profile's public content.\n",
    "  - When researching how to scroll through a page of unknown length in Selenium, I came across an approach that manipulates the `window` object directly to continue scrolling. Luckily, this direct approach works even after Instagram renders their soft login-wall to the page.\n",
    "3. Instagram dynamically populates and depopulates images from the browser as you scroll through a profile.\n",
    "  - To make sure that I capture all of the images as I scroll, I set up an algorithm that takes a 'snapshot' of the current HTML content of the page and then scrolls to the bottom of the page. Scrolling to the bottom of the page causes new content to render and old content to depopulate from the page. It then repeats this process of taking a snapshot and scrolling until it notices that the bottom of the page is no longer extending. I then extract all the image tags from the HTML snapshots and remove duplicates by running them through a set.\n",
    "4. After initial exploration, Instagram changed their preview of public profiles when a user is not logged in. Instead of automatically loading images upon scrolling to the bottom of the page, they currently show a few images and a 'show more' button.\n",
    "  - To get the page back into a state where images load automatically upon scrolling, I had to use Chrome Dev Tools to identify potential class names to use in targeting the 'show more' button element. With class names in hand I was able to write a few lines that tell the Selenium WebDriver how to locate the button and then to execute a click action on it. Once the button was clicked and scrolling was restored, the remainder of my previous code continued to work as expected.\n",
    "  - After writing the button clicking code, I noticed that only certain profiles have the 'show more' button enabled so I had to alter my approach to search for the button and click if it is present or proceed with scrolling as usual.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from random import randint\n",
    "\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snapshot(browser):\n",
    "    \"\"\"Appends the current HTML of the page to the \n",
    "    snapshots list.\n",
    "    \"\"\"\n",
    "    global snapshots\n",
    "    snapshots.append(browser.page_source)\n",
    "\n",
    "\n",
    "def scroll_and_snapshot(browser, max_scroll_secs):\n",
    "    \"\"\"Scrolls through the full height of a profile page while \n",
    "    frequently taking snapshots of the page's HTML.\n",
    "    \"\"\"\n",
    "    SCROLL_PAUSE_TIME = 1\n",
    "    last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "    end_time = time.time() + max_scroll_secs\n",
    "    \n",
    "    # Attribution for scrolling mechanism:\n",
    "    # https://stackoverflow.com/questions/20986631/how-can-i-scroll-a-web-page-using-selenium-webdriver-in-python#27760083\n",
    "    while time.time() < end_time:\n",
    "        # Scroll down to bottom\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        # Wait to load page\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        # Calculate new scroll height and compare with last scroll height\n",
    "        new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        snapshot(browser)\n",
    "        \n",
    "        if new_height <= last_height:\n",
    "            break\n",
    "        else: \n",
    "            last_height = new_height\n",
    "\n",
    "\n",
    "def collect_image_tags(snapshots):\n",
    "    \"\"\"Goes through the HTML snapshots and returns a set of unique \n",
    "    img elements.\n",
    "    \"\"\"\n",
    "    image_tags = []\n",
    "    \n",
    "    for html in snapshots:\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        image_tags += soup.find_all('img', class_='FFVAD')\n",
    "        \n",
    "    return set(image_tags)\n",
    "\n",
    "\n",
    "def capture(snapshots, browser):\n",
    "    \"\"\"Downloads all images from the provided HTML snapshots.\"\"\"  \n",
    "    image_tags = collect_image_tags(snapshots)\n",
    "\n",
    "    for index, image in enumerate(image_tags):\n",
    "        browser.get(image['src'])\n",
    "        images = browser.find_elements_by_tag_name('img')\n",
    "        # Edit file name f-string below  as needed\n",
    "        images[0].screenshot(f'./screenshot_{index}.png')\n",
    "        wait_time = randint(1, 2)\n",
    "        time.sleep(wait_time)\n",
    "\n",
    "\n",
    "def create_browser():\n",
    "    \"\"\"Returns a Selenium Chrome WebDriver instance.\"\"\"\n",
    "    browser = webdriver.Chrome('../utilities/chromedriver')\n",
    "    return browser\n",
    "\n",
    "\n",
    "def click_show_more_button(browser):\n",
    "    \"\"\"Clicks the troublesome 'show more' button, if present.\"\"\"\n",
    "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    try:\n",
    "        button = browser.find_element_by_class_name('z4xUb')\n",
    "        button.click()\n",
    "    except:\n",
    "        return"
   ]
  },
  {
   "source": [
    "## Result of Exploration\n",
    "\n",
    "Working with Selenium and the Instagram website led to the above collection of functions that work together to report on and optionally download images from a public profile."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Image Links Captured: 114\n"
    }
   ],
   "source": [
    "# Report back on a public profile with a link\n",
    "\n",
    "profile_name = 'third_impact_01'\n",
    "instagram_url = f'https://www.instagram.com/{profile_name}'\n",
    "max_scroll_secs = 300\n",
    "snapshots = []\n",
    "\n",
    "browser = create_browser()\n",
    "browser.get(instagram_url)\n",
    "click_show_more_button(browser)\n",
    "scroll_and_snapshot(browser, max_scroll_secs)\n",
    "images = collect_image_tags(snapshots)\n",
    "print(f'Image Links Captured: {len(images)}')\n",
    "\n",
    "# ONLY call line below if you want to risk downloading a lot of images\n",
    "# capture(snapshots, browser)\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "source": [
    "## Synthesizing Into Classes\n",
    "\n",
    "Below is an example of combining the above exploratory code into classes using the builder design pattern to make modelling public Instagram profiles easy and repeatable. Check out [`insta_builder.py`](https://github.com/SkylerBurger/apis_and_scrapers/blob/master/instagram/insta_builder.py) for a look under the hood at the code behind the classes."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from insta_builder import ProfileDirector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Director instance to build Profiles\n",
    "\n",
    "profile_director = ProfileDirector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell the Director to build a Profile with the given link\n",
    "\n",
    "profile_name = 'engineering.stations'\n",
    "insta_profile = profile_director.build_insta_profile(profile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "529\n"
    }
   ],
   "source": [
    "print(insta_profile.image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell the profile to download its images\n",
    "\n",
    "# Change value below to int, or leave as None to download all\n",
    "# max_images_to_download = None\n",
    "# instagram_profile.download_images(max_images_to_download)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('apis-and-scrapers': venv)",
   "language": "python",
   "name": "python38264bitapisandscrapersvenvf2140220de3048d48d920259101581f4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}